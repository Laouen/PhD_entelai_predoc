general:
  module_paths: ['/home/lbelloli/git/doctorado/PhD_entelai_predoc']
  save_path: ./
  verbose: 11
  pandas_sep: ;

data_preprocess:
  output_storage_type:
    X: npy
    y: npy
    features: npy
    class_labels: npy
    classes: npy
    processed_data: csv
  cache_output: Off
  function: entelai_predoc_modules.preprocess_data.preprocess_data
  parameters:
    curated_targets_file: ./data/predoc_fleni_targets_curada.xlsx
    df_predoc_responses_file: ./data/predoc_fleni_responses.csv
    target_schema: 'Migrañas_vs_otras' #'Migraña_sin_aura_vs_otras', 'Cefalea_secundaria_vs_resto', 'Migraña_vs_CTA', 'Migraña_sin_aura_vs_cefalea_tensional'

data_split:
  input_map:
    data_preprocess:
      X: 1
      y: 2
  output_storage_type: npy
  cache_output: On
  class: ConPipe.GraphNode.DataSplit.DataSplit
  parameters:
    function: sklearn.model_selection.train_test_split
    parameters:
      test_size: 0.25
      random_state: 42
      shuffle: On

data_augmentation:
  input_map:
    data_split:
      X_train: X
      y_train: y
  output_storage_type: npy
  cache_output: On
  function: entelai_predoc_modules.data_augmentation.data_augmentation
  parameters:
    multiple: 'balanced'

feature_selection:
  bypass_inout_map:
    X_train: X_train
    X_test: X_test
  bypass: On
  input_map:
    data_augmentation:
      X: X_train
      y: y_train
    data_split:
      X_test: X_test
  output_storage_type: npy
  cache_output: On
  function: entelai_predoc_modules.feature_selection.feature_selection

model_selection:
  input_map:
    feature_selection:
      X_train: X
    data_augmentation:
      y: y
  output_storage_type: 
    estimator: pickle 
    cv_results_: csv
  cache_output: On
  class: ConPipe.GraphNode.ModelSelection.ModelSelection
  parameters:
    parameter_optimizer: 
      class: sklearn.model_selection.GridSearchCV
      scoring: recall # esto tiene que poder ser una funcion custom desde el módulo también
      parameters: 
        refit: On
        n_jobs: -1
    cv: 
      class: sklearn.model_selection.StratifiedKFold 
      parameters:
        n_splits: 5
        shuffle: On
        random_state: 42
    models:
      LogisticRegression:
        class: sklearn.linear_model.LogisticRegression
        constructor_params:
          warm_start: False
          random_state: 42
          max_iter: 10000
          n_jobs: -1
        param_grid:
          C: [0.2, 0.4, 1, 100]
          penalty: ['l1','l2']
          solver: ['lbfgs', 'liblinear', 'saga']
        fit_params:
          sample_weight: null
      MultiLayerPerceptron:
        class: sklearn.neural_network.MLPClassifier
        constructor_params:
          solver: adam
          activation: relu
          shuffle: True
          batch_size: auto
          max_iter: 2000
          n_iter_no_change: 10
          random_state: 42
          tol: 0.0001
          warm_start: False
        param_grid:
          learning_rate_init: [0.01, 0.001, 0.0001]
          hidden_layer_sizes: [[62, 16, 8], [62, 16], [32, 8], [62]]
          alpha: [0, 0.0001, 0.01]
      RandomForestClasifier:
        class: sklearn.ensemble.RandomForestClassifier
        constructor_params:
          warm_start: False
          random_state: 42
          n_jobs: -1
        param_grid:
          max_depth: [3, 4, 6, 8]
          n_estimators: [200, 300, 500]
          min_samples_split: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        fit_params:
          sample_weight: null
      GradientBoostingClassifier:
        class: sklearn.ensemble.GradientBoostingClassifier
        constructor_params:
          warm_start: False
          random_state: 42
        param_grid:
          max_depth: [3, 4, 6, 8]
          n_estimators: [200, 300, 500]
          min_samples_split: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
      SupportVectorMachine:
        class: sklearn.svm.SVC
        constructor_params:
          random_state: 42
          probability: True
          class_weight: null
        param_grid:
          C: [1, 10, 100, 1000]
          kernel: ['rbf', 'sigmoid', 'poly']
          gamma: ['auto', 0.1, 0.01, 0.001]

feature_importance:
  input_map:
    model_selection:
      estimator: estimator
    feature_selection:
      X_train: X
    data_augmentation:
      y: y
  output_storage_type: npy
  cache_output: Off
  function: sklearn.inspection.permutation_importance
  parameters:
    scoring: recall
    random_state: 42

predict_train:
  input_map:
    model_selection:
      estimator: estimator
    feature_selection:
      X_train: X
    data_augmentation:
      y: y
  output_storage_type: npy
  cache_output: On
  class: ConPipe.GraphNode.ModelPrediction.ModelPrediction
  parameters:
    cv:
      class: sklearn.model_selection.StratifiedKFold 
      parameters:
        n_splits: 5
        shuffle: On
        random_state: 42

predict_test:
  input_map:
    model_selection:
      estimator: estimator
    feature_selection:
      X_test: X
    data_split:
      y_test: y
  output_storage_type: npy
  cache_output: On
  class: ConPipe.GraphNode.ModelPrediction.ModelPrediction

evaluate_test:
  input_map:
    data_preprocess:
      class_labels: class_labels
    predict_test:
      y_true: y_true
      y_pred: y_pred
      y_probas: y_probas
      classes: classes
  cache_output: Off
  class: ConPipe.GraphNode.ResultEvaluation.ResultEvaluation
  parameters:
    tag: test
    output_path: ./results # This parameter is overwrited by the command line
    scores:
      confusion_matrix:
        function: sklearn.metrics.confusion_matrix
        score_type: pred
      accuracy:
        function: sklearn.metrics.accuracy_score
        score_type: pred
      precision:
        function: sklearn.metrics.precision_score
        score_type: pred
        parameters:
          average: weighted
          pos_label: 1
      precision:
        function: sklearn.metrics.f1_score
        score_type: pred
        parameters:
          average: weighted
          pos_label: 1
      recall:
        function: sklearn.metrics.recall_score
        score_type: pred
        parameters:
          average: weighted
          pos_label: 1
    charts:
      roc:
        function: ConPipe.visualizations.roc_cruve_binary
      confusion_matrix: 
        function: ConPipe.visualizations.confusion_matrix_chart
        parameters:
          annot: On
          cmap: flare
          fmt: g

evaluate_train:
  input_map:
    data_preprocess:
      class_labels: class_labels
    predict_train:
      y_true: y_true
      y_pred: y_pred
      y_probas: y_probas
      classes: classes
  cache_output: Off
  class: ConPipe.GraphNode.ResultEvaluation.ResultEvaluation
  parameters:
    tag: train
    output_path: ./results # This parameter is overwrited by the command line
    scores:
      confusion_matrix:
        function: sklearn.metrics.confusion_matrix
        score_type: pred
      accuracy:
        function: sklearn.metrics.accuracy_score
        score_type: pred
      precision:
        function: sklearn.metrics.precision_score
        score_type: pred
        parameters:
          average: weighted
          pos_label: 1
      precision:
        function: sklearn.metrics.f1_score
        score_type: pred
        parameters:
          average: weighted
          pos_label: 1
      recall:
        function: sklearn.metrics.recall_score
        score_type: pred
        parameters:
          average: weighted
          pos_label: 1
    charts:
      roc:
        function: ConPipe.visualizations.roc_cruve_binary
      confusion_matrix: 
        function: ConPipe.visualizations.confusion_matrix_chart
        parameters:
          annot: On
          cmap: flare
          fmt: g